# üèóÔ∏è Architecture Technique : SmartPDF-RAG

Ce document d√©taille la conception interne, la gestion des donn√©es et les choix strat√©giques du syst√®me de **Retrieval-Augmented Generation (RAG)** mis en ≈ìuvre dans ce projet.

---

## 1. Pipeline de Traitement des Requ√™tes (Workflow)

Le syst√®me suit un processus s√©quentiel pour transformer une question utilisateur en une r√©ponse pr√©cise, sourc√©e et v√©rifiable.



### üîÑ √âtape 1 : Contextualisation (Query Rewriting)
Lorsqu'un utilisateur pose une question au milieu d'une conversation (ex: *"Peux-tu m'en donner plus de d√©tails ?"*), la question seule est souvent trop vague pour une recherche efficace.
* **Action** : Le syst√®me utilise le `REWRITE_PROMPT` pour fusionner l'historique et la question en une **requ√™te autonome**.
* **Objectif** : Maximiser la pertinence de la recherche lexicale en identifiant les mots-cl√©s exacts.

### üîç √âtape 2 : Recherche Documentaire (Retrieval)
La requ√™te reformul√©e est soumise au moteur de recherche local.
* **Algorithme** : **BM25Okapi** (Ranking statistique bas√© sur la fr√©quence inverse des documents).
* **Extraction** : Le syst√®me r√©cup√®re les **$k=4$** fragments (chunks) ayant le score de pertinence le plus √©lev√©.
* **Sources** : Chaque fragment conserve ses m√©tadonn√©es (nom du fichier, num√©ro de page).

### ‚úçÔ∏è √âtape 3 : Synth√®se et R√©ponse (Generation)
Le LLM (Google Gemini 1.5 Flash) re√ßoit un prompt final "augment√©" contenant les extraits trouv√©s.
* **Contrainte** : L'IA a l'ordre formel de ne pas inventer d'informations si la r√©ponse ne figure pas dans le contexte fourni (lutte contre les hallucinations).

---

## 2. Structure et Persistance des Donn√©es

Pour garantir un d√©marrage instantan√© sans re-parser les PDF √† chaque lancement, le projet utilise une indexation locale intelligente dans le dossier `bm25_index/`.



### üìÑ Le Manifeste (`manifest.json`)
Ce fichier agit comme un syst√®me de contr√¥le de version pour les documents.
* **Fingerprint (SHA-256)** : Une empreinte num√©rique unique g√©n√©r√©e √† partir du nom, de la taille et de la date de modification de tous les fichiers du dossier `PDF/`.
* **Logique de Cache** : Si le fingerprint calcul√© au d√©marrage est identique √† celui stock√©, le syst√®me charge l'index existant. Sinon, il d√©clenche une reconstruction automatique.

### üì¶ Le Stockage (`store.json`)
Contient la "m√©moire" textuelle du syst√®me :
* **Texts** : Les paragraphes d√©coup√©s (chunks) de 1000 caract√®res.
* **Metas** : Les informations sources (source, page) li√©es √† chaque paragraphe pour assurer la tra√ßabilit√©.

---

## 3. Strat√©gie de Prompt Engineering

L'efficacit√© du syst√®me repose sur deux prompts piliers :

### A. Le Prompt de Reformulation (`REWRITE_PROMPT`)
* **R√¥le** : "Nettoyeur" de contexte.
* **Logique** : Il transforme une intention humaine (parfois vague) en une requ√™te optimis√©e pour un algorithme statistique.

### B. Le Prompt Syst√®me (`MANUAL_PROMPT_TEMPLATE`)
* **Instruction d'Honn√™tet√©** : *"Si vous ne connaissez pas la r√©ponse, dites simplement que vous ne savez pas."*
* **Structuration** : Force l'IA √† utiliser des listes √† puces pour la clart√©.
* **Ancrage** : *"Utilisez uniquement les morceaux de contexte suivants."*

---

## 4. Choix de l'Algorithme : BM25 vs Vector Search

[Image comparing BM25 keyword matching vs vector embedding semantic search]

| Caract√©ristique | BM25 (Notre choix) | Recherche Vectorielle (FAISS) |
| :--- | :--- | :--- |
| **Type de recherche** | Lexicale (mots-cl√©s exacts). | S√©mantique (sens global). |
| **Pr√©cision** | Excellente sur les noms propres, codes et termes techniques. | Meilleure sur les concepts et les synonymes. |
| **Infrastructure** | **Z√©ro co√ªt**, calcul local ultra-l√©ger. | N√©cessite des mod√®les d'embeddings (payants ou lourds). |
| **Maintenance** | Fichiers JSON simples. | N√©cessite une gestion de base de donn√©es de vecteurs. |

---

## 5. Monitoring avec Langfuse

L'architecture int√®gre nativement le tra√ßage via Langfuse pour mesurer :
1.  **La Latence** : Temps de recherche vs temps de g√©n√©ration.
2.  **Le Co√ªt** : Consommation de tokens Gemini en temps r√©el.
3.  **Le D√©bogage** : Visualisation de l'√©tape de reformulation pour ajuster les prompts.